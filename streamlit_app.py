from openai import OpenAI
import streamlit as st
from prompts import create_prompt_clf, create_prompt_edit_text, create_prompt_split_clf
from utils import test_label, call_api_client

####################################################################################
# Config

# About text for the menu item
about = """
This app is a playground to experiment with LLM to detect toxic/violent language and convert it to neutral text
"""

# streamlit config
st.set_page_config(
    page_title="ToxLang Playground",
    layout="wide",
    menu_items={
        "About": about
    }
)

st.header("Enter a sentence to evaluate")

# Condense the layout
padding = 0
st.markdown(
    f""" <style>
    .reportview-container .main .block-container{{
        padding-top: {padding}rem;
        padding-right: {padding}rem;
        padding-left: {padding}rem;
        padding-bottom: {padding}rem;
    }} </style> """,
    unsafe_allow_html=True,
)

# load custom css styles
with open(".streamlit/custom.css") as f:
    st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

# Dictionary for LLM selection
llm_available = {
    "Open AI: gpt-3.5-turbo":"gpt-3.5-turbo",
    "Open AI: gpt-4": "gpt-4",
}

# LLM temperature
TEMPERATURE = 0

# System content for classifying toxic language
system_content_clf = create_prompt_clf()

####################################################################################
# Left column

sidebar = st.sidebar

with sidebar:

    # Custom page title and subtitle
    st.title("ToxLang")
    st.markdown("<br>", unsafe_allow_html=True)
    st.subheader("Detect and correct toxic language", divider="orange")
    st.markdown("<br>", unsafe_allow_html=True)

    # Get OpenAI ley from user
    openai_label = "Enter your [OpenAi key](https://platform.openai.com/account/api-keys)"
    OPENAI_KEY = st.text_input(label=openai_label, type="password", help="Enter your OpenAi key")

    # Add space between elements of the column
    st.markdown("<br>", unsafe_allow_html=True)
    
    # Initialize chat history
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Selectbox with the list of LLM
    help_selectbox_llm = "This option is for when we will use open-source LLM"
    selected_llm = st.selectbox("Select a LLM", options=llm_available.keys(), help=help_selectbox_llm)
    if selected_llm and OPENAI_KEY:
        LLM_MODEL = llm_available[selected_llm]
        # Initialize LLM
        if "client" not in st.session_state:
            st.session_state.client = OpenAI(api_key=OPENAI_KEY)
    
    # Add space between elements of the column
    st.markdown("<br>", unsafe_allow_html=True)

    # Toggle to select whether split the text and classify it    
    if "split_clf" not in st.session_state:
        # Initialize split_clf
        st.session_state.split_clf = False
    help_toggle_split_clf = "Split the text into chunks and classify them"
    st.session_state.split_clf = st.toggle("Split and classify?", value=False, help=help_toggle_split_clf)

####################################################################################
# Chat

# Display chat messages from history on app rerun
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"], unsafe_allow_html=True)
    
# React to user input
if user_text := st.chat_input("How may I help you?"):
    # Display user message in chat message container
    st.chat_message("user").markdown(user_text)
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": user_text})

    if OPENAI_KEY:
        if not st.session_state.split_clf:
            # Detect toxic language
            selected_label, token_usage = call_api_client(
                api_client= st.session_state.client,
                llm_model=LLM_MODEL,
                system_prompt=system_content_clf,
                user_text=user_text,
                temperature=TEMPERATURE)
            completion_tokens, prompt_tokens, total_tokens = token_usage
            # Check if the label generated by the model belongs to the list of expected categories
            is_label_in_expected_categories = test_label(selected_label)
    
            if is_label_in_expected_categories:
                # The model chose a label that is in the list of expected categories
    
                # Edit text
                system_content_edit = create_prompt_edit_text(selected_label)
                edited_text, token_usage = call_api_client(
                    api_client= st.session_state.client,
                    llm_model=LLM_MODEL,
                    system_prompt=system_content_edit,
                    user_text=user_text,
                    temperature=TEMPERATURE)
                edited_text = f"Suggested correction:<br><font style='background-color: #FFFF00'>{edited_text}</font>"
                completion_tokens_edit, prompt_tokens_edit, total_tokens_edit = token_usage
                completion_tokens += completion_tokens_edit
                prompt_tokens += prompt_tokens_edit
                total_tokens += prompt_tokens_edit
                
                # Dict with token usage
                used_tokens = {
                    "completion_tokens":completion_tokens,
                    "prompt_tokens":prompt_tokens,
                    "total_tokens":total_tokens
                }
                
                # Prepare response for user
                text_for_response = f"This sentence is labeled as <b style='color: red'>{selected_label}</b><br><br>{edited_text}"
    
            else:
                # The model chose a label that is not in the list of expected categories
                text_for_response = "Something went wrong, the model choose an unexpected category!"
        
        elif st.session_state.split_clf:
            prompt_split_clf = create_prompt_split_clf(user_text)
            user_text_split_clf, token_usage = call_api_client(
                api_client= st.session_state.client,
                llm_model=LLM_MODEL,
                system_prompt="",
                user_text=prompt_split_clf,
                temperature=TEMPERATURE)
            
            # Dict with token usage
            completion_tokens, prompt_tokens, total_tokens = token_usage
            used_tokens = {
                "completion_tokens":completion_tokens,
                "prompt_tokens":prompt_tokens,
                "total_tokens":total_tokens
            }

            # Prepare response for user
            text_for_response = f"{user_text_split_clf}"
        
        response_for_user = f"{text_for_response}<br><br>(token usage: {used_tokens})"

    else:
        response_for_user = "Please add your OpenAI key to continue."

    # Display response in chat message container
    with st.chat_message("assistant"):
        st.markdown(response_for_user, unsafe_allow_html=True)
    # Add response to chat history
    st.session_state.messages.append({"role": "assistant", "content": response_for_user})
