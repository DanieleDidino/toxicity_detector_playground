{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import environ\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "# from pathlib import Path\n",
    "\n",
    "# Import OpenAI key\n",
    "env = environ.Env()\n",
    "environ.Env.read_env()\n",
    "API_KEY = env(\"OPENAI_API_KEY\")\n",
    "openai.api_key = API_KEY\n",
    "\n",
    "# Set constanst\n",
    "LLM_MODEL = \"gpt-3.5-turbo\"\n",
    "TEMPERATURE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = f\"\"\"\n",
    "You are an expert non-violent comunication.\n",
    "Your task is to identify toxic language.\n",
    "Always answer using three labels:\n",
    " - 'neutral': use this category for neutral non-toxic language.\n",
    " - 'toxic': use this category for toxic or violent language.\n",
    " - 'unclear': use this category is you don't know what category select.\n",
    "You must provide me with a label that classify the sentence provided below.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='neutral', role='assistant', function_call=None, tool_calls=None)\n",
      "CompletionUsage(completion_tokens=1, prompt_tokens=107, total_tokens=108)\n"
     ]
    }
   ],
   "source": [
    "completion = client_openai.chat.completions.create(\n",
    "  model=LLM_MODEL,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": system_content},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ],\n",
    "  temperature=TEMPERATURE,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n",
    "print(completion.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_sentence(client_openai, system_content, user_content, LLM_MODEL, TEMPERATURE):\n",
    "    completion = client_openai.chat.completions.create(\n",
    "        model=LLM_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": user_content}\n",
    "        ],\n",
    "        temperature=TEMPERATURE,\n",
    "    )\n",
    "\n",
    "    selected_label = completion.choices[0].message.content\n",
    "    used_tokens = {\n",
    "        \"completion_tokens\":completion.usage.completion_tokens,\n",
    "        \"prompt_tokens\":completion.usage.prompt_tokens,\n",
    "        \"total_tokens\":completion.usage.total_tokens\n",
    "    }\n",
    "\n",
    "    return selected_label, used_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "{'completion_tokens': 2, 'prompt_tokens': 103, 'total_tokens': 105}\n"
     ]
    }
   ],
   "source": [
    "label, token_dict = clf_sentence(client_openai, system_content, \"what the fuck are you talking about?\", LLM_MODEL, TEMPERATURE)\n",
    "\n",
    "print(label)\n",
    "print(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_sentences = [\n",
    "    # Toxic sentences\n",
    "    \"You don't deserve me.\",\n",
    "    \"You're pathetic.\",\n",
    "    \"I hate you.\",\n",
    "    \"You're a bad parent.\",\n",
    "    \"You're being crazy.\",\n",
    "    \"You're so needy\",\n",
    "    # Neutral sentences\n",
    "    \"Oh! That reminds me I have to put my doctor's appointment in my calendar.\",\n",
    "    \"Stop asking if I'm okay. Everything is fine\",\n",
    "    \"These are not the droids you are looking for\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = []\n",
    "\n",
    "for toxic_sentence in toxic_sentences:\n",
    "    # print(toxic_sentence)\n",
    "    label, _ = clf_sentence(\n",
    "        client_openai,\n",
    "        system_content,\n",
    "        toxic_sentence,\n",
    "        LLM_MODEL,\n",
    "        TEMPERATURE)\n",
    "    # print(label)\n",
    "    label_list.append((toxic_sentence, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"You don't deserve me.\", 'toxic'),\n",
       " (\"You're pathetic.\", 'toxic'),\n",
       " ('I hate you.', 'toxic'),\n",
       " (\"You're a bad parent.\", 'toxic'),\n",
       " (\"You're being crazy.\", 'toxic'),\n",
       " (\"You're so needy\", 'toxic'),\n",
       " (\"Oh! That reminds me I have to put my doctor's appointment in my calendar.\",\n",
       "  'neutral'),\n",
       " (\"Stop asking if I'm okay. Everything is fine\", 'neutral'),\n",
       " ('These are not the droids you are looking for', 'neutral')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split text and idenfy toxic sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_split_clf(user_text):\n",
    "    \"\"\"\n",
    "    Build a prompt to use in OpenAI client.\n",
    "    This prompt describes how to split the text into chunks and classify them based on the categories described in the f-string below.\n",
    "\n",
    "    Args: user_text (str): Text to split and classify.\n",
    "\n",
    "    Returns:\n",
    "        A prompt\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Objective: Split the provided text into chunks based on the following categories: \n",
    "    'criticism', 'contempt', 'defensiveness', 'stonewalling', 'neutral'.\n",
    "    If a text chunk does not belong to any specified category, classify it as \"other.\"\n",
    "    \n",
    "    Categories Defined:\n",
    "    \n",
    "        1. 'criticism': This style involves ad hominem attacks on a partner's character rather than addressing specific issues, distinguishing it from a complaint, which targets a specific behavior.\n",
    "        2. 'contempt': An extreme form of criticism, characterized by treating a partner with disrespect, sarcasm, and mockery, making them feel despised and worthless.\n",
    "        3. 'defensiveness': A response to criticism where one attempts to excuse their behavior and avoid taking responsibility, often resulting in blame-shifting.\n",
    "        4. 'stonewalling': It occurs when one partner withdraws from the interaction, shutting down communication in response to contempt.\n",
    "        5. 'neutral': This category is used for text that does not exhibit negative communication patterns nor explicitly fits into the categories of criticism, contempt, defensiveness, or stonewalling.\n",
    "            It includes statements or behaviors that are constructive, positive, or at least not harmful or negative in the context of a relationship.\n",
    "            Use this category for communication that is understanding, supportive, factual without emotional charge, or otherwise not indicative of conflict.\n",
    "        6. 'unclear': Use this category if the text does not clearly fit into any of the above categories or if it is ambiguous.\n",
    "    \n",
    "    Instructions:\n",
    "    \n",
    "        1. Read the text thoroughly.\n",
    "        2. Identify and extract chunks of text that belong to the specified categories.\n",
    "        3. Label each chunk with the corresponding category name.\n",
    "        4. If a text chunk does not fit any of the specified categories, label it as \"Other.\"\n",
    "        5. Present the categorized text chunks in the following format:\n",
    "    \n",
    "    Format:\n",
    "    \n",
    "        Category: [Category Name]\n",
    "        Text: [Extracted Text Chunk]\n",
    "    \n",
    "        Category: [Category Name/Other]\n",
    "        Text: [Extracted Text Chunk]\n",
    "    \n",
    "    (Repeat this format for each identified chunk.)\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    Given Text: \"Why would I do that to you? Are you seriously blaming me for everything? I understand your feelings, and I'm sorry for causing you pain. Maybe you should take a look at your own actions before pointing fingers at me! Let me explain the reasons behind my actions so we can better understand each other.\"\n",
    "    \n",
    "    Expected Output:\n",
    "    \n",
    "    Category: criticism\n",
    "    Text: Why would I do that to you? Are you seriously blaming me for everything?\n",
    "    \n",
    "    Category: neutral\n",
    "    Text: I understand your feelings, and I'm sorry for causing you pain.\n",
    "    \n",
    "    Category: criticism\n",
    "    Text: Maybe you should take a look at your own actions before pointing fingers at me!\n",
    "    \n",
    "    Category: neutral\n",
    "    Text: Let me explain the reasons behind my actions so we can better understand each other.\n",
    "    \n",
    "    Please proceed with categorizing the following text: {user_text}\n",
    "    \"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_text = text = \"What's wrong with me? What's wrong with you for even asking that? Can't you see I'm fine? Why are you always trying to start something.\"\n",
    "\n",
    "prompt = create_prompt_split_clf(usr_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, token_dict = clf_sentence(client_openai, \"\", prompt, LLM_MODEL, TEMPERATURE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: criticism\n",
      "Text: What's wrong with me?\n",
      "\n",
      "Category: contempt\n",
      "Text: What's wrong with you for even asking that?\n",
      "\n",
      "Category: neutral\n",
      "Text: Can't you see I'm fine?\n",
      "\n",
      "Category: criticism\n",
      "Text: Why are you always trying to start something.\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_dialogue_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
